# Use the official Python 3.10 Alpine image
FROM python:3.10-alpine

# Set the working directory inside the container
WORKDIR /app

# Install necessary system packages, including librdkafka development files
RUN apk add --no-cache \
    gcc \
    libc-dev \
    libffi-dev \
    g++ \
    openjdk11-jre \
    bash \
    wget \
    librdkafka-dev \
    make \
    && wget https://repo1.maven.org/maven2/org/apache/spark/spark-sql-kafka-0-10_2.12/3.3.0/spark-sql-kafka-0-10_2.12-3.3.0.jar -P /opt/bitnami/spark/jars/

# Remove unnecessary APK cache to reduce image size
RUN rm -rf /var/lib/apt/lists/*

# Copy the application code and requirements.txt into the container
COPY . /app

# Install Python dependencies using pip
RUN pip install --no-cache-dir -r requirements.txt

# Set environment variables for Java (required for Spark)
ENV JAVA_HOME=/usr/lib/jvm/java-11-openjdk
ENV PATH=$JAVA_HOME/bin:$PATH

# Expose Spark's default port (for debugging purposes)
EXPOSE 4040

# Run the PySpark Streaming job when the container starts
CMD ["python", "src/streaming_job.py"]
